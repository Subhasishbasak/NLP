{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TA_Assignment_4_MDS201803.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subhasishbasak/NLP/blob/master/Probability_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EePnqaMRW",
        "colab_type": "text"
      },
      "source": [
        "## TA_Assignment_4/MDS201803"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTa3m7T1aDDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pickle\n",
        "import random\n",
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opOStgYzbLbB",
        "colab_type": "code",
        "outputId": "903ba4e2-4e62-4ab4-f467-77c78767038a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXAvKH7iapAp",
        "colab_type": "code",
        "outputId": "e363784a-b933-46f0-caef-2655ed16d06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoPrmXsoa5cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('/content/drive/My Drive/CorpusFileName.txt')\n",
        "raw = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2FSoqKaguUy",
        "colab_type": "text"
      },
      "source": [
        "Preprcessing of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxaVNx9shK5o",
        "colab_type": "text"
      },
      "source": [
        "In this section we remove some unnecessary symbols (for e.g \\n, =, → etc.). Since we dont want this symbols to come when we are predicting the next most probable word using our language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFVRbrqlgr4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw = re.sub(\"\\n\",\" \",raw)         # removing newline command\n",
        "raw = re.sub(\"=\",\" \",raw)          # removing '=' symbol\n",
        "raw = re.sub(\"→\",\" \",raw)          # removing '→' symbol        \n",
        "raw = re.sub(\"[#$%&\\'()*+-/<=>?@[\\\\]^_`{|}~\\\"]\",\"\",raw)  # symbols not commonly used in bengali literature and hence we remove them    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ET9fcVhIno",
        "colab_type": "text"
      },
      "source": [
        "Extracting sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAW0Bxm8hHVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This code takes the raw preprocessed corpus and breakes it into sentences.\n",
        "# Each sentence is read as a list of words in \"sentence_corpus\" list\n",
        "\n",
        "sentence_corpus = []\n",
        "sentence = str()\n",
        "for i in raw:\n",
        "  if i == '।':\n",
        "    temp = sentence.split(' ')\n",
        "    if '' in temp:\n",
        "      temp.remove('')       # removing whitespace\n",
        "    sentence_corpus.append(temp)\n",
        "    sentence = str()\n",
        "  else:\n",
        "    sentence = sentence + i  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-OVLj26ELJn",
        "colab_type": "text"
      },
      "source": [
        "Creating the 3-gram language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6U_0gEBag5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a dictionary for model\n",
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# This code creates the trigrams from the sentences and creates a dictionary with the first 2 tokens as keys and the target token as value\n",
        "for sentence in sentence_corpus:\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "          model[(w1, w2)][w3] += 1\n",
        " \n",
        "# This code transforms the counts into relative frequencies (probabilities)\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZUwHeY3G9Ei",
        "colab_type": "text"
      },
      "source": [
        "To find the most probable starting words of a Bengali sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqyNqInFWs0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This dictionary stores all the unique starting words of the sentences and their frequencies. This helps to identify the most probable starting words.\n",
        "first_word = {}\n",
        "for i in sentence_corpus:\n",
        "    if i != [] and i[0] != '':\n",
        "      try:\n",
        "        first_word[i[0]] += 1\n",
        "      except KeyError:\n",
        "        first_word[i[0]] = 1\n",
        "\n",
        "# We sort the dictionary w.r.t their frequencies\n",
        "sorted_x = sorted(first_word.items(), key=lambda kv: kv[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOzf02iMYtaS",
        "colab_type": "code",
        "outputId": "318d8109-685f-4497-cba5-21cd6455fd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# The top 10 most probable starting words are :\n",
        "sorted_x[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('এই', 72236),\n",
              " ('তিনি', 47698),\n",
              " ('এটি', 33586),\n",
              " ('তার', 29004),\n",
              " ('এর', 23802),\n",
              " ('যদিও', 17318),\n",
              " ('১৯৩৭সালে', 17306),\n",
              " ('এ', 16559),\n",
              " ('উকাইর', 16445),\n",
              " ('তাদের', 16345)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1V3qOGKbLdT",
        "colab_type": "code",
        "outputId": "945e803c-c092-4941-b4c4-f088ade04874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# In our 3-gram model we take the two starting tokens ['এই', 'বাংলা'] and print all the following words along with their probabilities\n",
        "dict(model['এই', 'ছিল'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'অষ্টাদশ': 0.03125,\n",
              " 'আমাদের': 0.03125,\n",
              " 'এই': 0.03125,\n",
              " 'এক': 0.03125,\n",
              " 'একটি': 0.03125,\n",
              " 'ক্যাপ্টেন': 0.03125,\n",
              " 'গাসানীয়': 0.03125,\n",
              " 'চলচ্চিত্র': 0.03125,\n",
              " 'তাঁর': 0.03125,\n",
              " 'তার': 0.125,\n",
              " 'না': 0.03125,\n",
              " 'প্রথম': 0.03125,\n",
              " 'প্রথাগত': 0.03125,\n",
              " 'বাইজেন্টাইন': 0.03125,\n",
              " 'মনে': 0.03125,\n",
              " 'যে': 0.25,\n",
              " 'রুট': 0.03125,\n",
              " 'শেষ': 0.03125,\n",
              " 'শেষকৃত্যের': 0.03125,\n",
              " 'সংলাপ': 0.03125,\n",
              " 'সাধারণ': 0.03125,\n",
              " 'সেই': 0.03125}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQx8rsdiWuis",
        "colab_type": "text"
      },
      "source": [
        "Predicting sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtnD1u3eTjXS",
        "colab_type": "code",
        "outputId": "32137053-e083-45c8-bacf-5479c05428a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# The following code is used to generate sentences for a given pair of tokens \n",
        "# Here we start with the pair of words ['এই', 'ছিল'], since 'এই' is the most probable starting word for our corpus.\n",
        "\n",
        "# Given two words the following code extracts the most probable next word using the Tri-gram model and appends it to the sentence. \n",
        "# In the next step the last two words of this sentence is considered and the same step is followed to generate the next word.\n",
        "\n",
        "text = ['এই', 'ছিল']\n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "\n",
        "  max_prob = .0\n",
        "\n",
        "  for word in model[tuple(text[-2:])].keys():\n",
        "        if max_prob < model[tuple(text[-2:])][word]:    # Take the next word with maximum probability\n",
        "            max_prob = model[tuple(text[-2:])][word]    \n",
        "            most_probable_word = word\n",
        "  text.append(most_probable_word)\n",
        "\n",
        "  if text[-2:] == [None, None]:                       \n",
        "      sentence_finished = True\n",
        "      text.append('।')                                  # Appends the symbol '।' after sentence reaches its end\n",
        " \n",
        "\n",
        "print (\"Generated sentence : \\n\", ' '.join([t for t in text if t]))\n",
        "\n",
        "print(\"\\nThe length of the generated sentence is : \", len(' '.join([t for t in text if t]).split(' ')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated sentence : \n",
            " এই ছিল যে রাজনৈতিক ক্ষমতা সাবাহদের অধীনে চলে যায়; বাণিজ্যিক পরিবারেরা বাণিজ্যের উপর খেয়াল রাখত যেখানে হাউজ অব সাবাহ এবং অন্যান্য উল্লেখযোগ্য কুয়েতি পরিবারেরা কুয়েতের দেয়ালের ভেতর গড়ে উঠা শহরগুলোতে নিরাপত্তা প্রদান করত ।\n",
            "\n",
            "The length of the generated sentence is :  34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GkeiUjXBdYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}